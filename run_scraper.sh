#!/bin/bash
# Run distributed scraper in background with proper logging

echo "ğŸš€ Starting Distributed Facebook Ad Scraper..."
echo "ğŸ“Š Processing 246 keywords with 5 workers Ã— 10 threads"
echo ""

# Run scraper and redirect all output to a log file
cd product-research-tool-starter 2>/dev/null || true
nohup python3 distributed_scraper.py > scraper_main.log 2>&1 &

SCRAPER_PID=$!
echo "âœ… Scraper started with PID: $SCRAPER_PID"
echo "ğŸ“ Main log: scraper_main.log"
echo "ğŸ“ Worker logs: logs/worker_*.log"
echo ""
echo "Monitor progress with:"
echo "  tail -f scraper_main.log"
echo "  tail -f logs/worker_1.log"
echo ""
echo "Stop scraper with: kill $SCRAPER_PID"
